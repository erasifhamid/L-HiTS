{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c35de2b-1d25-4d12-a571-9003c704eb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## clear ram\n",
    "# import torch\n",
    "# with torch.no_grad():\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e431e4b5-6c13-4c60-8850-9207b8904105",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ad5989f-4f6c-4980-b8cb-9c21f22a93ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "########## imports  ##############\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import integrate, interpolate\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pickle\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Path for various functions\n",
    "module_path= os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "criterion = torch.nn.MSELoss(reduction='none')\n",
    "import ResNet as net\n",
    "from utils import *\n",
    "from Autoencoder import *\n",
    "from aHiTs import *\n",
    "import lstmrnn\n",
    "print('Libraries imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c221a1-ef25-41b7-8f85-8bace2f50f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "noise = 0.0 \n",
    "system = 'FHN'  \n",
    "data_dir = os.path.join('../data/', system)\n",
    "model_dir = os.path.join('../models/', system)\n",
    "path_to_result=os.path.join('../results/', system)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be37e1ce-a0e4-418f-905c-7d319a45e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b54843-ef91-4713-95f2-331b878855a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load(data_dir + \"/train_data.pt\")\n",
    "val_data = torch.load(data_dir + \"/val_data.pt\")\n",
    "test_data = torch.load(data_dir + \"/test_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5035e1d9-8e5d-4b62-a2e7-466f99a5c71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 5121, 100]),\n",
       " torch.Size([10, 51200, 100]),\n",
       " torch.Size([10, 51200, 100]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "# train_data = np.load(os.path.join(data_dir, 'train_noise{}.npy'.format(noise)))\n",
    "# val_data = np.load(os.path.join(data_dir, 'val_noise{}.npy'.format(noise)))\n",
    "# test_data = np.load(os.path.join(data_dir, 'test_noise{}.npy'.format(noise)))\n",
    "n_train = train_data.shape[0]\n",
    "n_val = val_data.shape[0]\n",
    "n_test = test_data.shape[0]\n",
    "train_data=torch.tensor(train_data).to(torch.float32)\n",
    "# train_data = train_data\n",
    "# sets=train_data.shape[0]\n",
    "# dataloader=torch.utils.data.DataLoader(x, batch_size=sets)\n",
    "train_data.shape,test_data.shape,val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e45113-b516-47a6-87ac-3222f5ecb9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params for AE\n",
    "input_size=train_data.shape[2]\n",
    "hidden_size=2 # select the appropriate size for the latent vector\n",
    "L1=100 \n",
    "L2=100\n",
    "L3=100\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, L1, L2, L3, input_size, hidden_size):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, L1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(L1, L2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(L2, L3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(L3, hidden_size)\n",
    "        )\n",
    "        # Building an linear decoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # The Sigmoid activation function\n",
    "        # outputs the value between 0 and 1\n",
    "        # 9 ==> 784\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size, L3),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(L3, L2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(L2, L1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(L1,input_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "    \n",
    "Autoencoder = AE(L1,L2,L3,input_size=input_size, hidden_size=hidden_size).to(device)\n",
    "\n",
    "\n",
    "#Params for ResNet\n",
    "tspan=encoded.shape[1]\n",
    "np.random.seed(2)  # for reproduction\n",
    "dt = 0.01  #0.001\n",
    "train_steps = tspan  # at least equal to the largest step size\n",
    "val_steps =tspan\n",
    "test_steps = tspan  # t=20\n",
    "t = np.linspace(0, (train_steps-1)*dt, train_steps)\n",
    "datasets.append(DataSet(z_train, z_valid, z_test, dt, step_size=step_size, n_forward=5)\n",
    "\n",
    "datasets = list()\n",
    "step_sizes = list()\n",
    "print('Dt\\'s: ')\n",
    "#a=[10,20,30,60,100,200,400,600,800]\n",
    "for i in range(10,11):\n",
    "    step_size = 2**i  #exponential function\n",
    "    step_sizes.append(step_size)\n",
    "    datasets.append(DataSet(z_train, z_valid, z_test, dt, step_size=step_size, n_forward=5))\n",
    "\n",
    "models = list()\n",
    "# max_epoch=20000\n",
    "L1=128\n",
    "L2=256\n",
    "L3=512\n",
    "L4=1024\n",
    "L5=2048\n",
    "z=hidden_size\n",
    "\n",
    "for (step_size, dataset) in zip(step_sizes, datasets):\n",
    "    # set up the network\n",
    "    model_name = 'modelnew_D{}_noise{}.pt'.format(step_size,noise)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    ResNet = net.ResNet(arch=[z,L1,L1,L1,z], dt=dt, step_size=step_size)\n",
    "    models.append(modelresnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e734a-9538-489b-a6d7-464a8624eb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "reconstruction_loss = nn.MSELoss()\n",
    "time_stepping_loss = nn.MSELoss()\n",
    "\n",
    "# Define optimizer\n",
    "AE_RN = nn.ModuleList([Autoencoder(), ResNet()])\n",
    "optimizer = optim.Adam(AE_RN.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for data in train_data:\n",
    "        # Forward pass for AE\n",
    "        z_train, train_reconstructed = AE_RN[0](data)\n",
    "        z_valid, val_reconstructed = AE_RN[0](val_data)\n",
    "        z_test, test_reconstructed = AE_RN[0](test_data)\n",
    "        # prepare data for ResNet\n",
    "        net.DataSet(encoded, z_valid, z_test, dt, step_size=step_size, n_forward=5)\n",
    "        n_samples = dataset.n_train\n",
    "        new_idxs = torch.randperm(n_samples)\n",
    "        batch_x = dataset.train_x[new_idxs[:batch_size], :]\n",
    "        batch_ys = dataset.train_ys[new_idxs[:batch_size], :, :]\n",
    "        # =============== calculate losses ================\n",
    "        train_loss = self.calculate_loss(batch_x, batch_ys, w=w)\n",
    "        val_loss = self.calculate_loss(dataset.val_x, dataset.val_ys, w=w)\n",
    "        \n",
    "        def calculate_loss(self, x, ys, w=1.0):\n",
    "        \"\"\"\n",
    "        :param x: x batch, array of size batch_size x n_dim\n",
    "        :param ys: ys batch, array of size batch_size x n_steps x n_dim\n",
    "        :return: overall loss\n",
    "        \"\"\"\n",
    "        batch_size, n_steps, n_dim = ys.size()\n",
    "        assert n_dim == self.n_dim\n",
    "        \n",
    "        \n",
    "        # forward (recurrence)\n",
    "        y_preds = torch.zeros(batch_size, n_steps, n_dim).float().to(self.device)\n",
    "        y_prev = x\n",
    "        for t in range(n_steps):\n",
    "            y_next = self.forward(y_prev)\n",
    "            y_preds[:, t, :] = y_next\n",
    "            y_prev = y_next\n",
    "\n",
    "        # compute loss\n",
    "        criterion = torch.nn.MSELoss(reduction='none')\n",
    "        loss = w * criterion(y_preds, ys).mean() + (1-w) * criterion(y_preds, ys).max()\n",
    "\n",
    "        return loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        estimated = AE_RN[1](latent)\n",
    "        \n",
    "        # Compute losses\n",
    "        reconstruction_loss_value = reconstruction_loss(data, reconstructed)# AE loss\n",
    "        time_stepping_loss_value = time_stepping_loss(latent, estimated)\n",
    "        total_loss = reconstruction_loss_value + time_estimation_loss_value\n",
    "        \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print training progress\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Reconstruction Loss: {reconstruction_loss_value.item()}, Time Estimation Loss: {time_estimation_loss_value.item()}\")\n",
    "    losses.append(total_loss.item())\n",
    "\n",
    "# Plot the combined loss function\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Combined Loss Function')\n",
    "plt.show()\n",
    "\n",
    "# After training, test the model\n",
    "with torch.no_grad():\n",
    "    test_latent, test_reconstructed = ae_resnet[0](test_data)\n",
    "    test_estimated = ae_resnet[1](test_latent)\n",
    "\n",
    "    # Print reconstruction loss and time estimation loss for testing\n",
    "    reconstruction_test_loss = reconstruction_loss(test_data, test_reconstructed)\n",
    "    time_estimation_test_loss = time_estimation_loss(test_latent, test_estimated)\n",
    "    print(f\"Testing Reconstruction Loss: {reconstruction_test_loss.item()}\")\n",
    "    print(f\"Testing Time Estimation Loss: {time_estimation_test_loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
