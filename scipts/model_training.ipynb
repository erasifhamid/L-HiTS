{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asif Hamid bhat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is a template for training various models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### clear ram\n",
    "# import torch\n",
    "# with torch.no_grad():\n",
    "#     torch.cuda.empty_cache()\n",
    "# %reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = os.path.abspath(os.path.join('../src/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path) \n",
    "from Autoencoder import *\n",
    "from utils import *\n",
    "import ResNet as net\n",
    "# import lstmrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adjustables\n",
    "k = list(range(11))           \n",
    "dt = 0.01  \n",
    "model_prefix='KS'\n",
    "system = 'KS'         # system name: \"\"FHN\",\"KS\n",
    "noise = 0.0                    \n",
    "hidden_size=8\n",
    "lr = 1e-3                     # learning rate\n",
    "max_epoch = 10000            # the maximum training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "data_dir = os.path.join('../data/', system)\n",
    "model_dir = os.path.join('../models/', system)\n",
    "path_to_result=os.path.join('../results/', system)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# global const\n",
    "n_forward = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 5121, 120]),\n",
       " torch.Size([5, 5121, 120]),\n",
       " torch.Size([5, 5121, 120]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = torch.load(data_dir + \"/train_data.pt\")\n",
    "val_data = torch.load(data_dir + \"/val_data.pt\")\n",
    "test_data = torch.load(data_dir + \"/test_data.pt\")\n",
    "train_data=train_data[:10,:,:]\n",
    "\n",
    "n=train_data.shape[2]\n",
    "n_train = train_data.shape[0]\n",
    "\n",
    "train_data.shape,val_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data=torch.tensor(train_data)\n",
    "train_data = train_data.to(torch.float32).to(device)\n",
    "sets=train_data.shape[0]\n",
    "dataloader=torch.utils.data.DataLoader(train_data, batch_size=32) ### 32 for FHN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model and train\n",
    "######Define the autoencoder class\n",
    "input_size=train_data.shape[2]\n",
    "L1=120  ### 100,100,100 for fhn and 120,120,100 for KS\n",
    "L2=120\n",
    "L3=100\n",
    "modelAE = AE(L1,L2,L3,input_size, hidden_size).to(device)\n",
    "num_epochs = 5000 # 5,000 for both FHN,KS\n",
    "learning_rate = 1e-3\n",
    "aemodel='/AE_{}.pt'.format(hidden_size)\n",
    "save_path=model_dir+aemodel\n",
    "train(modelAE, dataloader, num_epochs=num_epochs, learning_rate=1e-3,model_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####Load FHN AE BEST models\n",
    "modelAE.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 5121, 10]),\n",
       " torch.Size([5, 5121, 10]),\n",
       " torch.Size([5, 5121, 10]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data for latent dimension\n",
    "z_train=modelAE.encoder(train_data)\n",
    "z_valid=modelAE.encoder(torch.tensor(val_data[:,:,:]).to(torch.float32).to(device))\n",
    "z_test=modelAE.encoder(torch.tensor(test_data[:,:,:]).to(torch.float32).to(device))\n",
    "z_train.shape,z_valid.shape,z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Set wise training HIts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5121, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train1=z_train\n",
    "data=z_train1#.reshape(z_train1.shape[0]*z_train1.shape[1],z_train1.shape[2])\n",
    "data=data.cpu().detach().numpy()\n",
    "n_steps = data.shape[1] - 1\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: KS_D1_h10\n",
      "epoch 1000, training loss 0.0007058691699057817, validation loss 0.0008411856251768768\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.0004134595219511539, validation loss 0.0004330627270974219\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.0004702173755504191, validation loss 0.00040564732626080513\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.00032227145857177675, validation loss 0.0003826737229246646\n",
      "(--> new model saved @ epoch 4000)\n",
      "epoch 5000, training loss 0.0003899821313098073, validation loss 0.00038749989471398294\n",
      "epoch 6000, training loss 0.0002578617713879794, validation loss 0.0003761422703973949\n",
      "(--> new model saved @ epoch 6000)\n",
      "epoch 7000, training loss 0.0003352499916218221, validation loss 0.0003616265021264553\n",
      "(--> new model saved @ epoch 7000)\n",
      "epoch 8000, training loss 0.00034778594272211194, validation loss 0.00035482741077430546\n",
      "(--> new model saved @ epoch 8000)\n",
      "epoch 9000, training loss 0.00039841534453444183, validation loss 0.00040269765304401517\n",
      "epoch 10000, training loss 0.0001730529620544985, validation loss 0.0002633297990541905\n",
      "(--> new model saved @ epoch 10000)\n",
      "epoch 11000, training loss 0.00022869794338475913, validation loss 0.0002559119602665305\n",
      "(--> new model saved @ epoch 11000)\n",
      "epoch 12000, training loss 0.00030877129756845534, validation loss 0.00033523220918141305\n",
      "epoch 13000, training loss 0.0002640770690049976, validation loss 0.0003279979864601046\n",
      "epoch 14000, training loss 0.00019923174113500863, validation loss 0.00020528871391434222\n",
      "(--> new model saved @ epoch 14000)\n",
      "epoch 15000, training loss 0.00024233461590483785, validation loss 0.0002600989246275276\n",
      "epoch 16000, training loss 0.00019959556811954826, validation loss 0.00020548819156829268\n",
      "epoch 17000, training loss 0.00019294675439596176, validation loss 0.00023617305851075798\n",
      "epoch 18000, training loss 0.00013267160102259368, validation loss 0.00017478252993896604\n",
      "(--> new model saved @ epoch 18000)\n",
      "epoch 19000, training loss 0.00019518747285474092, validation loss 0.00018296226335223764\n",
      "epoch 20000, training loss 0.00018492912931833416, validation loss 0.00017507692973595113\n",
      "MODEL: KS_D2_h10\n",
      "epoch 1000, training loss 0.002984807128086686, validation loss 0.0028377750422805548\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.0014021402457728982, validation loss 0.001834280788898468\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.0018392306519672275, validation loss 0.0014567752368748188\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.0016949251294136047, validation loss 0.0015529970405623317\n",
      "epoch 5000, training loss 0.0011443407274782658, validation loss 0.001236850512214005\n",
      "(--> new model saved @ epoch 5000)\n",
      "epoch 6000, training loss 0.0012929586227983236, validation loss 0.0014424400869756937\n",
      "epoch 7000, training loss 0.001017761300317943, validation loss 0.0009852981893345714\n",
      "(--> new model saved @ epoch 7000)\n",
      "epoch 8000, training loss 0.0007271690992638469, validation loss 0.0008506713202223182\n",
      "(--> new model saved @ epoch 8000)\n",
      "epoch 9000, training loss 0.0013898930046707392, validation loss 0.0014881218085065484\n",
      "epoch 10000, training loss 0.0007461770437657833, validation loss 0.0008572989609092474\n",
      "epoch 11000, training loss 0.001303328899666667, validation loss 0.001501081744208932\n",
      "epoch 12000, training loss 0.0004655088414438069, validation loss 0.0006952516851015389\n",
      "(--> new model saved @ epoch 12000)\n",
      "epoch 13000, training loss 0.0009974958375096321, validation loss 0.0009051761007867754\n",
      "epoch 14000, training loss 0.0004556937492452562, validation loss 0.0006001086439937353\n",
      "(--> new model saved @ epoch 14000)\n",
      "epoch 15000, training loss 0.0007372566033154726, validation loss 0.0008335979655385017\n",
      "epoch 16000, training loss 0.0006372120114974678, validation loss 0.0006749058375135064\n",
      "epoch 17000, training loss 0.0003881090087816119, validation loss 0.00045981802395544946\n",
      "(--> new model saved @ epoch 17000)\n",
      "epoch 18000, training loss 0.00039576052222400904, validation loss 0.00044802689808420837\n",
      "(--> new model saved @ epoch 18000)\n",
      "epoch 19000, training loss 0.00029463847749866545, validation loss 0.0004036469617858529\n",
      "(--> new model saved @ epoch 19000)\n",
      "epoch 20000, training loss 0.0004915172467008233, validation loss 0.0004548948199953884\n",
      "MODEL: KS_D4_h10\n",
      "epoch 1000, training loss 0.0033235549926757812, validation loss 0.0043440996669232845\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.002437593648210168, validation loss 0.003261606441810727\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.002550426870584488, validation loss 0.003152653807774186\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.0037909841630607843, validation loss 0.003799093421548605\n",
      "epoch 5000, training loss 0.002491030376404524, validation loss 0.0042023868300020695\n",
      "epoch 6000, training loss 0.0018309862352907658, validation loss 0.0017416274640709162\n",
      "(--> new model saved @ epoch 6000)\n",
      "epoch 7000, training loss 0.003054705448448658, validation loss 0.0019156315829604864\n",
      "epoch 8000, training loss 0.002029201714321971, validation loss 0.0030202821362763643\n",
      "epoch 9000, training loss 0.0022290421184152365, validation loss 0.0018217632314190269\n",
      "epoch 10000, training loss 0.0014653947437182069, validation loss 0.0017713869456201792\n",
      "epoch 11000, training loss 0.00132669135928154, validation loss 0.0018051286460831761\n",
      "epoch 12000, training loss 0.0013363459147512913, validation loss 0.0016679264372214675\n",
      "(--> new model saved @ epoch 12000)\n",
      "epoch 13000, training loss 0.0011236509308218956, validation loss 0.0017323318170383573\n",
      "epoch 14000, training loss 0.0013151817256584764, validation loss 0.0017916777869686484\n",
      "epoch 15000, training loss 0.0012573349522426724, validation loss 0.0014105492737144232\n",
      "(--> new model saved @ epoch 15000)\n",
      "epoch 16000, training loss 0.0018861943390220404, validation loss 0.0015414899680763483\n",
      "epoch 17000, training loss 0.0012688515707850456, validation loss 0.0015842485008761287\n",
      "epoch 18000, training loss 0.0005704605719074607, validation loss 0.0007943711243569851\n",
      "(--> new model saved @ epoch 18000)\n",
      "epoch 19000, training loss 0.0008806489058770239, validation loss 0.0007538064965046942\n",
      "(--> new model saved @ epoch 19000)\n",
      "epoch 20000, training loss 0.0013950663851574063, validation loss 0.0013224661815911531\n",
      "MODEL: KS_D8_h10\n",
      "epoch 1000, training loss 0.01691470295190811, validation loss 0.014389346353709698\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.016031919047236443, validation loss 0.013128134422004223\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.009146621450781822, validation loss 0.007721482776105404\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.007965932600200176, validation loss 0.007797425612807274\n",
      "epoch 5000, training loss 0.014905977062880993, validation loss 0.014766331762075424\n",
      "epoch 6000, training loss 0.009234735742211342, validation loss 0.009206158109009266\n",
      "epoch 7000, training loss 0.005620565265417099, validation loss 0.004445862956345081\n",
      "(--> new model saved @ epoch 7000)\n",
      "epoch 8000, training loss 0.005561480298638344, validation loss 0.004625887144356966\n",
      "epoch 9000, training loss 0.005175009835511446, validation loss 0.0036609505768865347\n",
      "(--> new model saved @ epoch 9000)\n",
      "epoch 10000, training loss 0.008001354523003101, validation loss 0.00641965726390481\n",
      "epoch 11000, training loss 0.002741066738963127, validation loss 0.003129121381789446\n",
      "(--> new model saved @ epoch 11000)\n",
      "epoch 12000, training loss 0.004786659963428974, validation loss 0.0036303121596574783\n",
      "epoch 13000, training loss 0.002421786542981863, validation loss 0.003258692566305399\n",
      "epoch 14000, training loss 0.004511289298534393, validation loss 0.0036249570548534393\n",
      "epoch 15000, training loss 0.005330818705260754, validation loss 0.0037654293701052666\n",
      "epoch 16000, training loss 0.00531343650072813, validation loss 0.006660644430667162\n",
      "epoch 17000, training loss 0.0018381191184744239, validation loss 0.0021351492032408714\n",
      "(--> new model saved @ epoch 17000)\n",
      "epoch 18000, training loss 0.0016545760445296764, validation loss 0.002003034343943\n",
      "(--> new model saved @ epoch 18000)\n",
      "epoch 19000, training loss 0.0011592342052608728, validation loss 0.001197621924802661\n",
      "(--> new model saved @ epoch 19000)\n",
      "epoch 20000, training loss 0.0026043588295578957, validation loss 0.0022394913248717785\n",
      "MODEL: KS_D16_h10\n",
      "epoch 1000, training loss 0.02856670320034027, validation loss 0.025154074653983116\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.025842461735010147, validation loss 0.023143555968999863\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.015477985143661499, validation loss 0.013475243002176285\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.010199547745287418, validation loss 0.00982354674488306\n",
      "(--> new model saved @ epoch 4000)\n",
      "epoch 5000, training loss 0.017041770741343498, validation loss 0.014691113494336605\n",
      "epoch 6000, training loss 0.015628362074494362, validation loss 0.014410759322345257\n",
      "epoch 7000, training loss 0.011495944112539291, validation loss 0.013135991990566254\n",
      "epoch 8000, training loss 0.009403912350535393, validation loss 0.013077467679977417\n",
      "epoch 9000, training loss 0.006224889773875475, validation loss 0.005287565290927887\n",
      "(--> new model saved @ epoch 9000)\n",
      "epoch 10000, training loss 0.0021920292638242245, validation loss 0.0017362503567710519\n",
      "(--> new model saved @ epoch 10000)\n",
      "epoch 11000, training loss 0.006846545729786158, validation loss 0.007624431978911161\n",
      "epoch 12000, training loss 0.007876959629356861, validation loss 0.008267391473054886\n",
      "epoch 13000, training loss 0.009726477786898613, validation loss 0.0063566043972969055\n",
      "epoch 14000, training loss 0.01164662092924118, validation loss 0.014978291466832161\n",
      "epoch 15000, training loss 0.008245992474257946, validation loss 0.008357018232345581\n",
      "epoch 16000, training loss 0.009064048528671265, validation loss 0.010175375267863274\n",
      "epoch 17000, training loss 0.007386885583400726, validation loss 0.0075924573466181755\n",
      "epoch 18000, training loss 0.014709542505443096, validation loss 0.014051239937543869\n",
      "epoch 19000, training loss 0.001566160935908556, validation loss 0.001424181624315679\n",
      "(--> new model saved @ epoch 19000)\n",
      "epoch 20000, training loss 0.0014439111109822989, validation loss 0.0013977695489302278\n",
      "(--> new model saved @ epoch 20000)\n",
      "MODEL: KS_D32_h10\n",
      "epoch 1000, training loss 0.061763592064380646, validation loss 0.05200672522187233\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.02943561039865017, validation loss 0.03242019563913345\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.022570934146642685, validation loss 0.02610190026462078\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.012906410731375217, validation loss 0.012509383261203766\n",
      "(--> new model saved @ epoch 4000)\n",
      "epoch 5000, training loss 0.08991840481758118, validation loss 0.08059480041265488\n",
      "epoch 6000, training loss 0.02961958758533001, validation loss 0.031131790950894356\n",
      "epoch 7000, training loss 0.00956583023071289, validation loss 0.008730541914701462\n",
      "(--> new model saved @ epoch 7000)\n",
      "epoch 8000, training loss 0.0025711164344102144, validation loss 0.002754094311967492\n",
      "(--> new model saved @ epoch 8000)\n",
      "epoch 9000, training loss 0.0025229351595044136, validation loss 0.00221783434972167\n",
      "(--> new model saved @ epoch 9000)\n",
      "epoch 10000, training loss 0.0017797222826629877, validation loss 0.0020774726290255785\n",
      "(--> new model saved @ epoch 10000)\n",
      "epoch 11000, training loss 0.0026250816881656647, validation loss 0.0025911766570061445\n",
      "epoch 12000, training loss 0.0014650594675913453, validation loss 0.0015918564749881625\n",
      "(--> new model saved @ epoch 12000)\n",
      "epoch 13000, training loss 0.001637917128391564, validation loss 0.0017876892816275358\n",
      "epoch 14000, training loss 0.0010551362065598369, validation loss 0.0010894451988860965\n",
      "(--> new model saved @ epoch 14000)\n",
      "epoch 15000, training loss 0.0017928661545738578, validation loss 0.001680330140516162\n",
      "epoch 16000, training loss 0.00861013401299715, validation loss 0.0066338954493403435\n",
      "epoch 17000, training loss 0.004901597276329994, validation loss 0.004553682636469603\n",
      "epoch 18000, training loss 0.0008383637759834528, validation loss 0.0007703003939241171\n",
      "(--> new model saved @ epoch 18000)\n",
      "epoch 19000, training loss 0.005196454469114542, validation loss 0.005349720362573862\n",
      "epoch 20000, training loss 0.0043717497028410435, validation loss 0.004571747966110706\n",
      "MODEL: KS_D64_h10\n",
      "epoch 1000, training loss 0.09191874414682388, validation loss 0.10396303236484528\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.018596449866890907, validation loss 0.017735641449689865\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.009777091443538666, validation loss 0.009384648874402046\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.010775642469525337, validation loss 0.01247338205575943\n",
      "epoch 5000, training loss 0.3181540369987488, validation loss 0.42211776971817017\n",
      "epoch 6000, training loss 0.019023997709155083, validation loss 0.021505126729607582\n",
      "epoch 7000, training loss 0.005353064276278019, validation loss 0.006473117042332888\n",
      "(--> new model saved @ epoch 7000)\n",
      "epoch 8000, training loss 0.009371469728648663, validation loss 0.009167946875095367\n",
      "epoch 9000, training loss 0.004420203622430563, validation loss 0.004949268419295549\n",
      "(--> new model saved @ epoch 9000)\n",
      "epoch 10000, training loss 0.0031029635574668646, validation loss 0.002571717370301485\n",
      "(--> new model saved @ epoch 10000)\n",
      "epoch 11000, training loss 0.005261921789497137, validation loss 0.005141116213053465\n",
      "epoch 12000, training loss 0.001600290765054524, validation loss 0.001260895631276071\n",
      "(--> new model saved @ epoch 12000)\n",
      "epoch 13000, training loss 0.0009892812231555581, validation loss 0.0010859019821509719\n",
      "(--> new model saved @ epoch 13000)\n",
      "epoch 14000, training loss 0.002584869274869561, validation loss 0.0022221289109438658\n",
      "epoch 15000, training loss 0.06731756776571274, validation loss 0.057012416422367096\n",
      "epoch 16000, training loss 0.00936096627265215, validation loss 0.009098038077354431\n",
      "epoch 17000, training loss 0.0009888213826343417, validation loss 0.0012070093071088195\n",
      "epoch 18000, training loss 0.0019078516634181142, validation loss 0.002692857524380088\n",
      "epoch 19000, training loss 0.0019693560898303986, validation loss 0.0021961121819913387\n",
      "epoch 20000, training loss 0.009334538131952286, validation loss 0.010938846506178379\n",
      "MODEL: KS_D128_h10\n",
      "epoch 1000, training loss 0.2686770558357239, validation loss 0.29515549540519714\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.04722730442881584, validation loss 0.04677949473261833\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.027764655649662018, validation loss 0.025629818439483643\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.013045128434896469, validation loss 0.01295817457139492\n",
      "(--> new model saved @ epoch 4000)\n",
      "epoch 5000, training loss 0.01730119250714779, validation loss 0.01366061344742775\n",
      "epoch 6000, training loss 0.028900563716888428, validation loss 0.03153519332408905\n",
      "epoch 7000, training loss 0.021393923088908195, validation loss 0.021109404042363167\n",
      "epoch 8000, training loss 0.006975770462304354, validation loss 0.0053955260664224625\n",
      "(--> new model saved @ epoch 8000)\n",
      "epoch 9000, training loss 0.01211004238575697, validation loss 0.012743856757879257\n",
      "epoch 10000, training loss 0.3419780731201172, validation loss 0.29801562428474426\n",
      "epoch 11000, training loss 0.006214874796569347, validation loss 0.0044287387281656265\n",
      "(--> new model saved @ epoch 11000)\n",
      "epoch 12000, training loss 0.0020207948982715607, validation loss 0.0019526459509506822\n",
      "(--> new model saved @ epoch 12000)\n",
      "epoch 13000, training loss 0.0029755234718322754, validation loss 0.0030243664514273405\n",
      "epoch 14000, training loss 0.006288672331720591, validation loss 0.004888106137514114\n",
      "epoch 15000, training loss 0.001812702277675271, validation loss 0.0019083524821326137\n",
      "(--> new model saved @ epoch 15000)\n",
      "epoch 16000, training loss 0.584220826625824, validation loss 0.5153630375862122\n",
      "epoch 17000, training loss 0.007487897295504808, validation loss 0.008311279118061066\n",
      "epoch 18000, training loss 0.0004677408142015338, validation loss 0.0005741781205870211\n",
      "(--> new model saved @ epoch 18000)\n",
      "epoch 19000, training loss 0.00011168114724569023, validation loss 0.00013565196422860026\n",
      "(--> new model saved @ epoch 19000)\n",
      "epoch 20000, training loss 0.0020807781256735325, validation loss 0.0021948902867734432\n",
      "MODEL: KS_D256_h10\n",
      "epoch 1000, training loss 0.17529501020908356, validation loss 0.18179135024547577\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.0955190435051918, validation loss 0.0981876403093338\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.9854769706726074, validation loss 1.0469261407852173\n",
      "epoch 4000, training loss 0.009701348841190338, validation loss 0.009506633505225182\n",
      "(--> new model saved @ epoch 4000)\n",
      "epoch 5000, training loss 0.016220422461628914, validation loss 0.016424737870693207\n",
      "epoch 6000, training loss 0.17111191153526306, validation loss 0.16375958919525146\n",
      "epoch 7000, training loss 0.0059226155281066895, validation loss 0.005915091838687658\n",
      "(--> new model saved @ epoch 7000)\n",
      "epoch 8000, training loss 0.2159709930419922, validation loss 0.2042551040649414\n",
      "epoch 9000, training loss 0.27305537462234497, validation loss 0.2513333559036255\n",
      "epoch 10000, training loss 0.02569005824625492, validation loss 0.028697744011878967\n",
      "epoch 11000, training loss 0.0028742270078510046, validation loss 0.0030621467158198357\n",
      "(--> new model saved @ epoch 11000)\n",
      "epoch 12000, training loss 0.004243461415171623, validation loss 0.004108326975256205\n",
      "epoch 13000, training loss 0.00045594872790388763, validation loss 0.0004369528032839298\n",
      "(--> new model saved @ epoch 13000)\n",
      "epoch 14000, training loss 0.00020998418040107936, validation loss 0.0002381951198913157\n",
      "(--> new model saved @ epoch 14000)\n",
      "epoch 15000, training loss 0.0005371389561332762, validation loss 0.0005269349785521626\n",
      "epoch 16000, training loss 0.0003444212197791785, validation loss 0.0003670807636808604\n",
      "epoch 17000, training loss 0.0027109794318675995, validation loss 0.0024380178656429052\n",
      "epoch 18000, training loss 0.0010921754874289036, validation loss 0.0011219349689781666\n",
      "epoch 19000, training loss 0.00014278505113907158, validation loss 0.00012543733464553952\n",
      "(--> new model saved @ epoch 19000)\n",
      "epoch 20000, training loss 0.0004356374847702682, validation loss 0.0005551759386435151\n",
      "MODEL: KS_D512_h10\n",
      "epoch 1000, training loss 0.10767979174852371, validation loss 0.10767979174852371\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.02413877286016941, validation loss 0.02413877099752426\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.005434127990156412, validation loss 0.005434127990156412\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.1496625542640686, validation loss 0.1496625542640686\n",
      "epoch 5000, training loss 0.04086534306406975, validation loss 0.04086533933877945\n",
      "epoch 6000, training loss 0.0008829133003018796, validation loss 0.0008829132420942187\n",
      "(--> new model saved @ epoch 6000)\n",
      "epoch 7000, training loss 0.00013329221110325307, validation loss 0.00013329221110325307\n",
      "(--> new model saved @ epoch 7000)\n",
      "epoch 8000, training loss 0.04972511902451515, validation loss 0.04972512274980545\n",
      "epoch 9000, training loss 0.0001496167533332482, validation loss 0.00014961676788516343\n",
      "epoch 10000, training loss 0.049360666424036026, validation loss 0.04936066269874573\n",
      "epoch 11000, training loss 7.27574952179566e-05, validation loss 7.275750249391422e-05\n",
      "(--> new model saved @ epoch 11000)\n",
      "epoch 12000, training loss 1.5953386537148617e-05, validation loss 1.595338835613802e-05\n",
      "(--> new model saved @ epoch 12000)\n",
      "epoch 13000, training loss 0.00011464358249213547, validation loss 0.00011464358249213547\n",
      "epoch 14000, training loss 1.5032489500299562e-05, validation loss 1.5032489500299562e-05\n",
      "(--> new model saved @ epoch 14000)\n",
      "epoch 15000, training loss 0.0003769570030272007, validation loss 0.0003769570030272007\n",
      "epoch 16000, training loss 1.7224658222403377e-05, validation loss 1.7224658222403377e-05\n",
      "epoch 17000, training loss 4.363096377346665e-05, validation loss 4.3630967411445454e-05\n",
      "epoch 18000, training loss 8.110731869237497e-05, validation loss 8.110731141641736e-05\n",
      "epoch 19000, training loss 0.0009328027372248471, validation loss 0.0009328027372248471\n",
      "epoch 20000, training loss 2.97701008094009e-05, validation loss 2.97701008094009e-05\n",
      "MODEL: KS_D1024_h10\n",
      "epoch 1000, training loss 0.006770055741071701, validation loss 0.006770056206732988\n",
      "(--> new model saved @ epoch 1000)\n",
      "epoch 2000, training loss 0.003779146820306778, validation loss 0.0037791470531374216\n",
      "(--> new model saved @ epoch 2000)\n",
      "epoch 3000, training loss 0.00042756315087899566, validation loss 0.00042756315087899566\n",
      "(--> new model saved @ epoch 3000)\n",
      "epoch 4000, training loss 0.00013458292232826352, validation loss 0.0001345829077763483\n",
      "(--> new model saved @ epoch 4000)\n",
      "epoch 5000, training loss 0.00015377855743281543, validation loss 0.00015377857198473066\n",
      "epoch 6000, training loss 0.0017397177871316671, validation loss 0.0017397176707163453\n",
      "epoch 7000, training loss 0.0003690643352456391, validation loss 0.0003690643352456391\n",
      "epoch 8000, training loss 0.0023727919906377792, validation loss 0.0023727919906377792\n",
      "epoch 9000, training loss 0.00021236874454189092, validation loss 0.0002123687299899757\n",
      "epoch 10000, training loss 3.26022673107218e-05, validation loss 3.26022673107218e-05\n",
      "(--> new model saved @ epoch 10000)\n",
      "epoch 11000, training loss 6.544858024426503e-07, validation loss 6.544858024426503e-07\n",
      "(--> new model saved @ epoch 11000)\n",
      "epoch 12000, training loss 1.4711979929415975e-05, validation loss 1.4711979019921273e-05\n",
      "epoch 13000, training loss 1.2101105895112596e-08, validation loss 1.2101106783291016e-08\n",
      "(--> new model saved @ epoch 13000)\n",
      "epoch 14000, training loss 3.8135614457979194e-12, validation loss 3.8135614457979194e-12\n",
      "(--> new model saved @ epoch 14000)\n",
      "--> model has reached an accuracy of 1e-8! Finished training!\n",
      "--> new model saved @ epoch 14001\n",
      "1621.5792562961578\n",
      "# of params:  23327854\n"
     ]
    }
   ],
   "source": [
    "### one set training \n",
    "# dummy parameter\n",
    "data=z_train1[:10,:,:]#.reshape(z_train1.shape[0]*z_train1.shape[1],z_train1.shape[2]).... can also use reshape option\n",
    "sets=z_train1.shape[0]\n",
    "data=data.cpu().detach().numpy()\n",
    "models = list()\n",
    "L1=128\n",
    "L2=256\n",
    "L3=512\n",
    "L4=1024\n",
    "L5=2048\n",
    "z=hidden_size\n",
    "dt = 1  \n",
    "n_forward=5\n",
    "step_sizes=[1,2,4,8,16,32,64,128,256,512,1024]\n",
    "# training\n",
    "max_epoch=20000\n",
    "start=time.time()\n",
    "n_steps = data.shape[1] - 1  # number of forward steps\n",
    "for step_size in step_sizes:\n",
    "    resdata = np.empty((0, step_size * n_forward + 1, z_train1.shape[2]))\n",
    "    for j in range(sets):\n",
    "        data=z_train1[j,:,:].cpu().detach().numpy()\n",
    "        m = int(np.ceil(n_steps/(step_size*n_forward)))\n",
    "        pdata = np.zeros((m, step_size*n_forward+1, data.shape[1]))\n",
    "        for i in range(m):\n",
    "            start_idx = i*step_size*n_forward\n",
    "            end_idx = start_idx + step_size*n_forward + 1\n",
    "            tmp = data[start_idx:end_idx, :]\n",
    "            pdata[i, :tmp.shape[0], :] = tmp\n",
    "        resdata = np.concatenate((resdata, pdata), axis=0)\n",
    "    pdata=resdata\n",
    "    dataset = net.DataSet(pdata, pdata, data[np.newaxis, :], dt, step_size, n_forward)\n",
    "    model_name = 'modelKS_D{}_h{}.pt'.format(step_size,hidden_size)\n",
    "    print('MODEL: '+model_prefix+'_D{}_h{}'.format(step_size,hidden_size))\n",
    "    model = net.ResNet(arch=[z,L4,L4,L4,z], dt=dt, step_size=step_size)\n",
    "    model.train_net(dataset, max_epoch=max_epoch, batch_size=32, lr=1e-3, model_path=os.path.join(model_dir, model_name))\n",
    "    models.append(model)\n",
    "end=time.time()\n",
    "train_time=end-start\n",
    "print(train_time)\n",
    "print('# of params: ', sum([sum(p.numel() for p in model.parameters() if p.requires_grad) for model in models]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
