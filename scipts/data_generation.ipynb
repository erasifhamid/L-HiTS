{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used for generating data sets for autoencoder based multiscale HiTS experiments. Here, we consider different canonical PDEs. Simulations are conducted using scipy.integrate.solve_ivp() and considered as ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import integrate\n",
    "from tqdm.notebook import tqdm\n",
    "import h5py\n",
    "import sys\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "# paths\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "system='RD' ### FHN,KS,RD\n",
    "data_dir = os.path.join('../data/', system)\n",
    "sys.path.append('../data/')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/RD'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FitzHugh-Nagumo (FHN) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FHN DATA IS GENERATED USIN LED DATA FOLDER BEST1 FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{split}\n",
    "\t\\epsilon \\mathbf{u}_t &= \\epsilon^2 \\mathbf{u}_{xx} + \\mathbf{f}(\\mathbf{u})-\\mathbf{v}+ 0.05  \n",
    "\\end{split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for test data FHN\n",
    "f = h5py.File('../data/FHN/FHN_data_test_10T.mat','r')\n",
    "rho_test = np.array(f['test_data'])\n",
    "snapshots_test=torch.tensor(np.transpose(rho_test,[2,1,0]))\n",
    "test_data=snapshots_test\n",
    "torch.save(test_data, data_dir + \"/test_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR VAL DATA\n",
    "f = h5py.File('../data/FHN/FHN_data_val_10T.mat','r')\n",
    "rho_val = np.array(f['val_data'])\n",
    "snapshots_val=torch.tensor(np.transpose(rho_val,[2,1,0]))\n",
    "val_data=snapshots_val\n",
    "torch.save(val_data, data_dir + \"/val_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/FHN/FHN_data3000_new.mat','r')\n",
    "#rho_train = f.get('train_data').value\n",
    "rho_train = np.array(f['train_data'])\n",
    "rho_val = np.array(f['val_data'])\n",
    "rho_test = np.array(f['test_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 5121, 100]),\n",
       " torch.Size([10, 5121, 100]),\n",
       " torch.Size([10, 5121, 100]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_t=1000\n",
    "n_v=10\n",
    "n_tes=10\n",
    "snapshots_train=torch.tensor(np.transpose(rho_train,[2,1,0])[:n_t,:,:])\n",
    "snapshots_valid=torch.tensor(np.transpose(rho_val,[2,1,0])[:n_v,:,:])\n",
    "snapshots_test=torch.tensor(np.transpose(rho_test,[2,1,0])[:n_tes,:,:])\n",
    "train_data=snapshots_train\n",
    "test_data=snapshots_test\n",
    "val_data=snapshots_valid\n",
    "noise = 0.0  \n",
    "train_data.shape,test_data.shape,val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FHN = os.path.join(data_dir,'FHN_data3000_new')\n",
    "# data = loadmat(FHN)  \n",
    "# train_data=data['train_data']\n",
    "# test_data=data['test_data']\n",
    "# val_data=data['val_data']\n",
    "# noise = 0.0       #noise levels: 0.0, 0.01, 0.02, 0.05 ,0.1, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data, data_dir + \"/train_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(train_data, data_dir + \"/train_data.pt\")\n",
    "# torch.save(val_data, data_dir + \"/val_data.pt\")\n",
    "# torch.save(test_data, data_dir + \"/test_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Noise to the data\n",
    "# train_data += noise*np.mean(np.std(train_data, axis=1))*np.random.randn(*train_data.shape)\n",
    "# val_data += noise*np.mean(np.std(val_data, axis=1))*np.random.randn(*val_data.shape)\n",
    "# test_data += noise*np.mean(np.std(test_data, axis=1))*np.random.randn(*test_data.shape)\n",
    "# #save data\n",
    "# np.save(os.path.join(data_dir,'train_noise{}.npy'.format(noise)), train_data)\n",
    "# np.save(os.path.join(data_dir,'val_noise{}.npy'.format(noise)), val_data)\n",
    "# np.save(os.path.join(data_dir,'test_noise{}.npy'.format(noise)), test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### KS EQUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\t\\mathbf{u}_t=-\\mathbf{u}\\mathbf{u}_x - \\mathbf{u}_{xx} -\\mathbf{u}_{xxxx}\n",
    "%\t\\frac{\\partial u}{\\partial t} = -u\\frac{\\partial u}{\\partial x} - \\frac{\\partial^2 u}{\\partial x^2} - \\frac{\\partial^4 u}{\\partial x^4}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_train\n",
    "# f_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for test data KS\n",
    "f = h5py.File('../data/KS/KS_test_L22_10T.mat','r')\n",
    "rho_test = np.array(f['test_data'])\n",
    "snapshots_test=torch.tensor(np.transpose(rho_test,[2,1,0]))\n",
    "test_data=snapshots_test\n",
    "test_data=test_data.transpose(1, 2)\n",
    "torch.save(test_data, data_dir + \"/test_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 51201, 120])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 5121, 120])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## train data for KS\n",
    "f_train1= h5py.File('../data/KS/KS_train_L22_1T.mat','r')\n",
    "rho_train1 = np.array(f_train1['train_data'])\n",
    "snapshots_train1=torch.tensor(np.transpose(rho_train1,[2,1,0]))\n",
    "train_data=snapshots_train1\n",
    "train_data=train_data.transpose(1, 2)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data, data_dir + \"/train_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data for KS\n",
    "# f_train1= h5py.File('../data/KS/KS_train_raw1.mat','r')\n",
    "# rho_train1 = np.array(f_train1['train_data1'])\n",
    "# snapshots_train1=torch.tensor(np.transpose(rho_train1,[2,1,0]))\n",
    "# f_train2= h5py.File('../data/KS/KS_train_raw2.mat','r')\n",
    "# rho_train2 = np.array(f_train2['train_data2'])\n",
    "# snapshots_train2=torch.tensor(np.transpose(rho_train2,[2,1,0]))\n",
    "# train_data=torch.cat((snapshots_train1, snapshots_train2))\n",
    "# torch.save(train_data, data_dir + \"/train_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data=torch.cat((snapshots_train1, snapshots_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(train_data, data_dir + \"/train_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for Validation data of KS\n",
    "f_val = h5py.File('../data/KS/KS_val_L22_10T.mat','r')\n",
    "rho_val = np.array(f_val['val_data'])\n",
    "snapshots_val=torch.tensor(np.transpose(rho_val,[2,1,0]))\n",
    "val_data=snapshots_val\n",
    "val_data=val_data.transpose(1, 2)\n",
    "torch.save(val_data, data_dir + \"/val_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 51201, 120]),\n",
       " torch.Size([200, 5121, 120]),\n",
       " torch.Size([5, 51201, 120]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape,train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RD Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data for RD\n",
    "T1=5120\n",
    "f_train1= h5py.File('../data/RD/RD_data.mat','r')\n",
    "# rho_train1 = np.array(f_train1['train_data'])\n",
    "# snapshots_train1=torch.tensor(np.transpose(rho_train1,[2,1,0]))\n",
    "# train_data=rho_train1\n",
    "# train_data=train_data.transpose(1, 2)\n",
    "# train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20480, 96, 96])\n",
      "torch.Size([20480, 2, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "u=f_train1['u'][:-1,:-4,:-4]\n",
    "v=f_train1['v'][:-1,:-4,:-4]\n",
    "u_tensor = torch.tensor(u).float()\n",
    "v_tensor = torch.tensor(v).float()\n",
    "org_data = torch.stack((u_tensor, v_tensor), dim=0)\n",
    "torch.max(org_data[0]-u_tensor)\n",
    "print(org_data.shape)\n",
    "# Reshape Data\n",
    "train_dataALL = org_data.permute(1,0,2,3)\n",
    "print(train_dataALL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15360"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1=5120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15360, 2, 96, 96]), torch.Size([5120, 2, 96, 96]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=train_dataALL[:-T1,:,:,:]\n",
    "val_data=train_dataALL[3*T1:,:,:,:]\n",
    "train_data.shape,val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# ax = sns.heatmap( train_data[-1,0] ,  cmap = 'coolwarm' )\n",
    "# ax.invert_yaxis()\n",
    "# plt.title( \"2-D Heat Map\" )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data, data_dir + \"/train_data.pt\")\n",
    "torch.save(val_data, data_dir + \"/val_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 50001, 100, 100])\n",
      "torch.Size([50001, 2, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "### for test data RD\n",
    "f = h5py.File('../data/RD/RD_test_data.mat','r')\n",
    "u_test = np.array(f['u'])\n",
    "v_test = np.array(f['v'])\n",
    "u_test_tensor = torch.tensor(u_test).float()\n",
    "v_test_tensor = torch.tensor(v_test).float()\n",
    "org_test_data = torch.stack((u_test_tensor, v_test_tensor), dim=0)\n",
    "torch.max(org_test_data[0]-u_test_tensor)\n",
    "print(org_test_data.shape)\n",
    "# Reshape Data\n",
    "test_dataALL = org_test_data.permute(1,0,2,3)\n",
    "print(test_dataALL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 2, 96, 96])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=-test_dataALL[:-1,:,:-4,:-4]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_data, data_dir + \"/test_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for Validation data of RD\n",
    "# f_val = h5py.File('../data/KS/KS_val_L22_10T.mat','r')\n",
    "# rho_val = np.array(f_val['val_data'])\n",
    "# snapshots_val=torch.tensor(np.transpose(rho_val,[2,1,0]))\n",
    "# val_data=snapshots_val\n",
    "# val_data=val_data.transpose(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
